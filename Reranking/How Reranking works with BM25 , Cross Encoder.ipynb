{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4075d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from sentence-transformers) (4.42.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from sentence-transformers) (2.3.1)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from sentence-transformers) (0.23.4)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-11.0.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 268.8/268.8 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading pillow-11.0.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.7/2.6 MB 21.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.2/2.6 MB 14.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.4/2.6 MB 12.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.0/2.6 MB 12.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.2/2.6 MB 10.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.5/2.6 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 9.1 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.0 MB 17.0 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.9/11.0 MB 23.8 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.9/11.0 MB 15.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.2/11.0 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 12.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.3/11.0 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.6/11.0 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.8/11.0 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 11.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.4/11.0 MB 11.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.3/11.0 MB 12.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.0 MB 13.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.0/11.0 MB 13.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.1/11.0 MB 14.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.3/11.0 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 13.9 MB/s eta 0:00:00\n",
      "Using cached scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, Pillow, joblib, scikit-learn, sentence-transformers\n",
      "Successfully installed Pillow-11.0.0 joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 sentence-transformers-3.3.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4adef2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"This is a list which containing sample documents.\",\n",
    "    \"keywords are important for keyword-based search.\",\n",
    "    \"Document analysis involves extracting keywords\",\n",
    "    \"Keyword-based search relies on sparse embeddings.\",\n",
    "    \"Understanding document structure aids in keyword extractions\",\n",
    "    \"Efficient keyword extraction enhances search accuracy.\",\n",
    "    \"Semantic similarity improves document retrieval performance.\",\n",
    "    \"Machine learning algorithms can optimize keyword extraction methods.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "135b09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fca9b1",
   "metadata": {},
   "source": [
    "## BM25 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb8d54c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "\n",
    "model_name = \"sentence-transformers/paraphrase-xlm-r-multilingual-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dff038a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akrivia\\miniconda3\\envs\\finetuning\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\akrivia\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-xlm-r-multilingual-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(model_name_or_path= model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a2c8e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_embedding = model.encode(documents)\n",
    "\n",
    "len(document_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bec2ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document_embedding[0]) # it is converting into 768 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d49940a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Natural language processing techniques enhance keyword extraction efficiency.\"\n",
    "\n",
    "query_embedding = model.encode(query)\n",
    "\n",
    "len(query_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5829631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d2e4813",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(np.array([query_embedding]),document_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13ab16c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16948141, 0.4626166 , 0.5446862 , 0.44123265, 0.55409193,\n",
       "        0.75214124, 0.550352  , 0.7448165 ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7e4774a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 4, 6, 2, 1, 3, 0], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_similarity = np.argsort(similarity[0])[::-1]\n",
    "sorted_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e621585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_document = [(documents[i], similarity[0][i]) for i in sorted_similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02b0df14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Efficient keyword extraction enhances search accuracy.', 0.75214124),\n",
       " ('Machine learning algorithms can optimize keyword extraction methods.',\n",
       "  0.7448165),\n",
       " ('Understanding document structure aids in keyword extractions', 0.55409193),\n",
       " ('Semantic similarity improves document retrieval performance.', 0.550352),\n",
       " ('Document analysis involves extracting keywords', 0.5446862),\n",
       " ('keywords are important for keyword-based search.', 0.4626166),\n",
       " ('Keyword-based search relies on sparse embeddings.', 0.44123265),\n",
       " ('This is a list which containing sample documents.', 0.16948141)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba384b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank_bm25 in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\akrivia\\miniconda3\\envs\\finetuning\\lib\\site-packages (from rank_bm25) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce147349",
   "metadata": {},
   "source": [
    "### Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25585c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a206c27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_4_doc = [doc[0] for doc in ranked_document[:4] ]\n",
    "len(top_4_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9e11331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Efficient', 'keyword', 'extraction', 'enhances', 'search', 'accuracy.'],\n",
       " ['Machine',\n",
       "  'learning',\n",
       "  'algorithms',\n",
       "  'can',\n",
       "  'optimize',\n",
       "  'keyword',\n",
       "  'extraction',\n",
       "  'methods.'],\n",
       " ['Understanding',\n",
       "  'document',\n",
       "  'structure',\n",
       "  'aids',\n",
       "  'in',\n",
       "  'keyword',\n",
       "  'extractions'],\n",
       " ['Semantic',\n",
       "  'similarity',\n",
       "  'improves',\n",
       "  'document',\n",
       "  'retrieval',\n",
       "  'performance.']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_top_4_doc = [doc.split() for doc in top_4_doc]\n",
    "\n",
    "tokenized_top_4_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d10b6d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'techniques',\n",
       " 'enhance',\n",
       " 'keyword',\n",
       " 'extraction',\n",
       " 'efficiency.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_token = query.split()\n",
    "query_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "270b702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25= BM25Okapi(tokenized_top_4_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6cb21b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18419519, 0.16152501, 0.17211681, 0.        ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_score = bm25.get_scores(query_token)\n",
    "bm25_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58e416d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_rerank_score = np.argsort(bm25_score)[::-1]\n",
    "sorted_rerank_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c1a78c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficient keyword extraction enhances search accuracy.\t- 0.18419518704069648\n",
      "Understanding document structure aids in keyword extractions\t- 0.1721168141199951\n",
      "Machine learning algorithms can optimize keyword extraction methods.\t- 0.16152501017414925\n",
      "Semantic similarity improves document retrieval performance.\t- 0.0\n"
     ]
    }
   ],
   "source": [
    "for idx in sorted_rerank_score:\n",
    "    print(f\"{top_4_doc[idx]}\\t- {bm25_score[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c619789",
   "metadata": {},
   "source": [
    "## from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "912ad2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56747db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akrivia\\miniconda3\\envs\\finetuning\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\akrivia\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfb060a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_a = \"The movie was fantastic!\"\n",
    "sentence_b = \"I really enjoy the film.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53d614ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode inputs\n",
    "inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt', padding=True,\n",
    "                  truncation=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0fc9e835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1996,  3185,  2001, 10392,   999,   102,  1045,  2428,  5959,\n",
       "          1996,  2143,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "82df6d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model output\n",
    "output = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "039c6a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.6578, -0.5613]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2beee622",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb978c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5e2763be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert logits to probabilities \n",
    "\n",
    "probs = torch.softmax(logits,dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1be0e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7719, 0.2281]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "423ad6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_score = probs[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e6bbb1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22809046506881714"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9fe5a2",
   "metadata": {},
   "source": [
    "## Cross Encoder\n",
    "- The input of the model always consist of a data pair for example two sentences, and output a value between **0 to 1** indicating **similarity score** of these sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ccce34ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a2fd21c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akrivia\\miniconda3\\envs\\finetuning\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\akrivia\\.cache\\huggingface\\hub\\models--cross-encoder--ms-marco-MiniLM-L-6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e0238c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Efficient keyword extraction enhances search accuracy.',\n",
       " 'Machine learning algorithms can optimize keyword extraction methods.',\n",
       " 'Understanding document structure aids in keyword extractions',\n",
       " 'Semantic similarity improves document retrieval performance.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ranked document\n",
    "top_4_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b22a8fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [[query,doc] for doc in top_4_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "65f23ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Natural language processing techniques enhance keyword extraction efficiency.',\n",
       "  'Efficient keyword extraction enhances search accuracy.'],\n",
       " ['Natural language processing techniques enhance keyword extraction efficiency.',\n",
       "  'Machine learning algorithms can optimize keyword extraction methods.'],\n",
       " ['Natural language processing techniques enhance keyword extraction efficiency.',\n",
       "  'Understanding document structure aids in keyword extractions'],\n",
       " ['Natural language processing techniques enhance keyword extraction efficiency.',\n",
       "  'Semantic similarity improves document retrieval performance.']]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b3ffb81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_encoder.predict(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "66f50592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.1378734 ,  0.84216833, -2.8850963 , -8.293585  ], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "126e75a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_docs = zip(scores,top_4_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "229efdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranked_document = sorted(scored_docs,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "43454032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.1378734, 'Efficient keyword extraction enhances search accuracy.'),\n",
       " (0.84216833,\n",
       "  'Machine learning algorithms can optimize keyword extraction methods.'),\n",
       " (-2.8850963, 'Understanding document structure aids in keyword extractions'),\n",
       " (-8.293585, 'Semantic similarity improves document retrieval performance.')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reranked_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa07921b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
